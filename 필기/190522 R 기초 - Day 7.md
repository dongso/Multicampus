# R 기초 - Day 7



## 한국 지도 시각화

Github에 올라와있는 함수를 바로 다운받아 쓸 수 있는 함수 `install_github`가 있다. 그걸 쓰기 위한 패키지 `devtools`를 설치한다.
```R
install.packages(("devtools"))
library(devtools)
```

```R
install_github("cardiomoon/kormaps2014")
library(kormaps2014)

str(changeCode(korpop1))
```

* changeCode(): UTF-8로 쓰여진 것을 CP949로 인코딩해준다.

### 우리나라 지도 출력

```R
library(ggiraphExtra)
library(ggplot2)
library(dplyr)

korpop1 <- rename(korpop1, pop = "총인구_명", dist_name = "행정구역별_읍면동")   # 한글은 오류가 생길 수 있으므로 영어로 바꿔준다.

ggChoropleth(data = korpop1,    # 지도에 표시할 데이터
             aes(fill = pop,    # 색상별로 표현할 변수
                 map_id = code,    # 지역 기준 변수
                 tooltip = name),    # 지도 위에 표시할 지역명
             map = kormap1,    # 지도 데이터
             interactive = T)    # 인터랙티브
```

### 지역 별 결핵 환자 수 시각화

```R
str(changeCode(tbc))
ggChoropleth(
  data = tbc,
  aes(fill = NewPts,
      map_id = code,
      tooltip = name),
  map = kormap1,
  interactive = T)
```



## interactive란?

```R
install.packages("plotly")
library(plotly)

p <- ggplot(data = mpg,
       aes(x = displ,
           y = hwy,
           col = drv))+
  geom_point()    # 기존 plot

ggplotly(p)    # interactive plot
```

### interactive 막대바

```R
str(diamonds)
d <- ggplot(data = diamonds,
       aes(x = cut,
           fill = clarity))+
  geom_bar(position = "dodge")
ggplotly(d)
```

### interactive한 시계열 그래프 (dygraphs)

```R
install.packages("dygraphs")
library(dygraphs)
# economics: 실업자 수와 저축률 사이 관계를 알 수 있는 데이터셋
str(economics)
head(economics)
# psavert: 개인 저축률
library(xts)
econ <- xts(economics$unemploy,
    order.by = economics$date)
head(econ)
dygraph(econ) %>% 
  dyRangeSelector()
```

### plot 하나에 두개의 data

```R
# 저축률
econ_a <- xts(economics$psavert,
    order.by = economics$date)
#실업자수
econ_b <- xts(economics$unemploy/1000,
    order.by = economics$date)
econ_a
econ_b

econ2 <- cbind(econ_a, econ_b)
econ2
str(econ2)
colnames(econ2)   # econ에 있는 열 이름들 출력
colnames(econ2) <- c("psavert", "unemploy")    # 열 이름들 바꾸기
head(econ2)

dygraph(econ2) %>% 
  dyRangeSelector()
```



## 학습 정리

변수에는 연속형 변수와 범주형 변수가 있다.

```R
exam <- read.csv("Data/csv_exam.csv")
exam
exam[]

exam [2,]   # 2번 행만 출력

# class가 1인 행 추출
exam %>% filter(class==1)
exam[exam$class==1,]

# 수학점수 80점 이상인 행 추출
exam[exam$math>=80,]

# 2반이면서 영어 점수가 70점 이상인 행 추출
exam[exam$class==2&exam$english>=70,]

# 영어 90점 미만이거나 과학이 50점 미만인 행 추출
exam[exam$english<90 | exam$science<50,]

# id열 추출
exam[,1]
exam[,"id"]

# class, math 열 추출
exam[,c("class", "math")]

# 1행 3열 추출
exam[1,3]

# 5행 math열 추출
exam[5,"math"]

# math가 50점 이상인 행에 대한 english열 추출
exam[exam$math>=50, "english"]

# math가 50점 이상인 행에 대한 english와 science열 추출
exam[exam$math>=50, c("english", "science")]

# 수학이 50점 이상, 영어가 80점 이상인 학생에 대해 각 반의 전과목 총 평균 출력
# dplyr 사용
exam %>% 
  filter(math>=50 & english>=80) %>% 
  mutate(avg=(math+english+science)/3) %>% 
  group_by(class) %>% 
  summarise(classmean=mean(avg))
# 내장 함수 사용
exam$avg <- (exam$math+exam$english+exam$science)/3
aggregate(data = exam[exam$math>=50 & exam$english>=80,],
          avg~class,
          mean)
```

```R
# mpg 데이터를 dplyr 패키지 사용해 class 중 compact와 suv 차종의 도시 및 고속도로 통합 연비에 대한 평균 출력
mpg %>% 
  filter(class=="compact" | class=="suv") %>% 
  mutate(totFE = (cty+hwy)/2) %>% 
  group_by(class) %>% 
  summarise(mean=mean(totFE))

# 연속형 변수 (Numeric): 산술연산 가능
# 범주형 변수 (Factor): 산술연산 불가능

var1 <- c(1,2,3,1,2)
var2 <- factor(c(1,2,3,1,2))
var1   # 수치형 변수
var2   # 범주형 변수
var1+3
var2+3   # 오류
class(var1)
class(var2)
levels(var2)
levels(var1)

var3 <- c("a","b","b","c")
var4 <- factor(c("a","b","b","c"))
var3   # 문자형
var4   # 범주형
class(var3)
class(var4)

mean(var1)
mean(var2)   # 오류
var2 <- as.numeric(var2)
class(var2)
mean(var2)
levels(var2)
```



## 데이터 구조

* 벡터(vector): 1차원, 한가지 변수 타입으로 구성
* 행렬(matrix): 2차원, 한가지 변수 타입으로 구성
* 데이터 프레임(data frame): 2차원, 다양한 변수 타입으로 구성
* 배열(array): 2차원 이상(다차원), 한가지 변수 타입으로 구성
* 리스트(list): 2차원 이상(다차원), 다양한 변수 타입으로 구성

```R
# 1. 벡터 (1개 이상의 값, 한 가지 타입)
a <- 1
a
b <- "hello"
b

# 2. 데이터프레임 (2차원, 다양한 타입)
x1 <- data.frame(v1=c(1,2,3),
                 v2=c("a","b","c"))
x1
class(x1)

# 3. 행렬 (2차원, 한 가지 타입)
x2 <- matrix(c(1:10), ncol=2)
x2
class(x2)

# 4. 배열 (2차원 이상, 한 가지  타입)
x3 <- array(1:20, dim = c(2,5,2))   # 2행, 5열, 깊이(차원) 2
x3

# 5. 리스트 (2차원 이상, 다양한 타입)
x4 <- list(f1=a,  # 벡터 
           f2=x1,   # 데이터프레임
           f3=x2,   # 매트릭스
           f4=x3)   # 배열
x4

# 함수의 리턴 결과가 리스트 타입인 경우가 많다.
x <- boxplot(mpg$cty)
class(x)
x$stats[,1]
x$stats[,1][4]
```



## 텍스트 마이닝

```R
myvector <- c(1:6, "a")
myvector
# 원래 벡터는 한가지 타입이어야 하기 때문에, 숫자와 문자가 같이 있으면 문자형으로 바뀐다.
class(myvector)

mylist <- list(1:6, "a")
mylist

obj1 <- 1:4
obj2 <- 6:10
obj3 <- list(obj1, obj2)
obj3

mylist <- list(obj1, obj2, obj3)
mylist
# 벡터로 구성된 자료 -> [] 사용
# 리스트 형식 -> [[]] 사용
mylist[[3]]
mylist[[3]][1]    # list
mylist[[3]][[1]]    # vector

mylist[[3]][[1]][2]

# unlist: 리스트를 벡터로 변환
myvector <- c(1:6, "a")
mylist <- list(1:6, "a")
unlist(mylist)
myvector
unlist(mylist)==myvector    # 둘이 같은지 비교

mylist[[1]][1:6]
mean(mylist[[1]][1:6])
unlist(mylist)
unlist(mylist)[1:6]
mean(unlist(mylist)[1:6])   # 오류남. 문자 벡터이기 때문.

name1 <- "Donald"
myspace <- " "
name2 <- "Trump"
list(name1, myspace, name2)
unlist(list(name1, myspace, name2))

name <- c("갑", "을", "병", "정")
gender <- c(2,1,1,2)
mydata <- data.frame(name, gender)
mydata
```

### attr

* attr(): object의 대상에 대한 속성을 지정해준다.

```R
attr(mydata$name, "what the variable means") <- "이름"
mydata$name
# 데이터에 대한 부가적인 설명을 하고자 할 때 attr 함수를 사용한다.
attr(mydata$gender, "what the variable means") <- "성별"
mydata$gender

mydata$gender.character <- attr(mydata$gender, "what the variable means")
mydata
```

### lapply

```R
mylist <- list(1:4, 6:10, list(1:4, 6:10))
mylist
# mylist 의 [[3]]번 평균 구하기
mylist[[3]]
lapply(mylist[[3]],mean)
```

* lapply 사용 시 주의할 점: lapply(적용하고자 하는 데이터, 함수)

```R
lapply(mylist,mean)   # [[3]]은 vector가 아니고 list라서 NA가 나온다.

lapply(mylist[c(1,2)],mean)

lapply(mylist[c(1,2, c(1,2))],mean)   # c(1,2)를 통해 list를 벡터화 했기 때문에 값이 나온다
```

### tapply

* tapply(벡터, 그룹화를 위한 색인, 함수)

```R
tapply(1:10, rep(1,10), sum)   # 1~10까지 모두가 1번 그룹이므로 합하면 55.
tapply(1:10, 1:10 %% 2 == 1, sum)

wordlist <- c("the", "is", "a", "the")
doc1freq <- c(3,4,2,4)
doc2freq <- rep(1,4)

tapply(doc1freq, wordlist, length)    # 빈도표
tapply(doc2freq, wordlist, length)
tapply(doc1freq, wordlist, sum)
tapply(doc2freq, wordlist, sum)
```

### 텍스트 마이닝 연습

```R
sent1 <- c("earth", "to", "earth")
sent2 <- c("ashes", "to", "ashes")
sent3 <- c("dust", "to", "dust")
# 한 문장에서 to는 한번, to가 아닌 단어는 두번 등장
# 총 3개의 문장에서 등장한 단어 빈도를 조사하려고 한다, tapply 함수를 이용하여.
rep(1, length(sent1))
myfreq<- c(rep(1, length(sent1)), rep(1, length(sent2)), rep(1, length(sent3)))
tapply(myfreq, c(sent1, sent2, sent3), sum)



mysentence <- "Learning R is so interesting"

# 단어 단위로 문장 분해
strsplit(mysentence, split=" ")

# 문자 단위로 단어 분해
mywords <- strsplit(mysentence, split=" ")
mywords[[1]]
mywords[[1]][5]
strsplit(mywords[[1]][5], split="")

# 각 단어들이 어떤 문자로 구성됐는지 표현
for (i in 1:5) {
  print(strsplit(mywords[[1]][i], split=""))
}

myletters <- list()
for (i in 1:5) {
  myletters[i] <- strsplit(mywords[[1]][i], split="")
}
myletters

paste(myletters[[1]], collapse = "")

mywords2 <- list()
for (i in 1:5){
  mywords2[i] <- paste(myletters[[i]], collapse = "")
}
mywords2

paste(mywords2, collapse=" ")
```

```R
R_wiki <- "R is a programming language and software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. Polls, surveys of data miners, and studies of scholarly literature databases show that R's popularity has increased substantially in recent years.
R is a GNU package. The source code for the R software environment is written primarily in C, Fortran, and R. R is freely available under the GNU General Public License, and pre-compiled binary versions are provided for various operating systems. While R has a command line interface, there are several graphical front-ends available."

R_wiki

# 1. 문단 단위로 분리
r_wiki_para <- strsplit(R_wiki, split="\n")
r_wiki_para   # 2개의 문단으로 분리됨

# 2. 문단을 문장 단위로 분리
r_wiki_sent <- strsplit(r_wiki_para[[1]], split = "\\." )    # .과 같은 특수문자를 쓸 때는 역슬래쉬 두개를 넣어줘야 한다.
r_wiki_sent

# 3. 문장을 단어 단위로 분리
class(r_wiki_sent)   # 리스트
class(r_wiki_sent[[1]])   # 벡터
# 각 벡터에 대해 따로따로 분리해주면 된다
strsplit(r_wiki_sent[[1]], split=" ")   # 결과가 또 list이다.
r_wiki_word <- list()
r_wiki_word[[1]] <- strsplit(r_wiki_sent[[1]], split=" ")
r_wiki_word

for (i in 1:2) {
  r_wiki_word[[i]] <- strsplit(r_wiki_sent[[i]], split=" ")
}
r_wiki_word

# r_wiki_word에 "language"라는 단어만 추출
r_wiki_word[[1]][[1]][5]
```

### regexpr

```R
mysentence <- "Learning R is so interesting"
regexpr("ing", mysentence)
# 결과에서
# 6: 매칭된 위치
# 3: 매칭된 길이
# chars: 결과 타입
class(regexpr("ing", mysentence))    # integer
as.vector(regexpr("ing", mysentence))   # regexpr의 맨 앞 요소만 남긴다 -> 시작 위치를 알 수 있다
loc.begin <- as.vector(regexpr("ing", mysentence))    # 시작 위치
# 매칭된 길이를 알고 싶을 때
attr(regexpr("ing", mysentence),
     "match.length")
loc.length <- attr(regexpr("ing", mysentence),     # 패턴(매칭된 것) 길이
     "match.length")
# 패턴 종료 위치
loc.end <- loc.begin+loc.length-1
loc.end



# 패턴을 한번만 찾는게 아니라 있는 건 다 찾고 싶을 때
gregexpr("ing", mysentence)
length(gregexpr("ing", mysentence)[[1]])    # 매칭된 문자열의 개수
loc.begin <- as.vector(gregexpr("ing", mysentence)[[1]])
loc.begin   # 패턴의 모든 발견 위치 저장
loc.length <- attr(gregexpr("ing", mysentence)[[1]],    # 매칭된 패턴 길이
     "match.length")
loc.end <- loc.begin+loc.length-1    # 패턴 종료 위치
```

### regexec

regexec 함수는 regexpr과 비슷(하지만 다르다)

```R
regexpr("interesting", mysentence)
regexec("interesting", mysentence)    # 이렇게 단순히 시작위치만 찾을때는 결과가 동일하다
# 하지만 regexec가 더 자유롭다
regexec("inte(r)estin(g)", mysentence)    # 시작 문자의 위치 뿐만 아니라 소괄호에 묶여있는 문자의 위치도 검색

regexec("so (intere(s)ting)", mysentence)    # 여러개 한번에 검색 가능

r_wiki_sent
mysentences <- unlist(r_wiki_sent)
# "software"라는 단어 검색
regexpr("software",mysentences)
  # 결과에 값이 7개 나오는 이유 = mysentences에 문장이 7개라서
  # -1의 의미 = 결과가 안나왔다
# "software"라는 단어가 2회 이상 등장한 적이 있는지 여부 확인
gregexpr("software",mysentences)    # 없다

mytemp <- regexpr("software",mysentences)
my.begin <- as.vector(mytemp)
my.begin
# my.begin에서 -1은 결측처리
my.begin[my.begin==-1] <- NA
my.begin
attr(mytemp, "match.length")   # 패턴 길이
my.begin+attr(mytemp, "match.length")-1   # 패턴 종료 위치
my.end <- my.begin+attr(mytemp, "match.length")-1

matrix(NA, nrow=length(my.begin), ncol=2)    # 모두 초기값이 NA인 7행 2열의 행렬
mylocs <- matrix(NA, nrow=length(my.begin), ncol=2)

# mylocs에 시작위치와 끝위치를 넣으려고 한다

colnames(mylocs) <- c("begin", "end")
mylocs
paste("sentence", 1:length(my.begin))
paste("sentence", 1:length(my.begin), sep=".")
rownames(mylocs) <- paste("sentence", 1:length(my.begin), sep=".")
mylocs

my.begin
my.end

cbind(my.begin, my.end)
cbind(my.begin[1], my.end[1])

for (i in 1:length(my.begin)){
  mylocs[i,] <- cbind(my.begin[i], my.end[i])
}
mylocs
```

### grep

```R
grep("software", mysentences)   # 결과: 1, 2, 5번 문장에서 단어가 발견되었다.
grepl("software", mysentences)   # 논리형으로 결과 도출
```

### sub

```R
mysentence
# ing를 ING로 치환
sub("ing", "ING", mysentence)    # 두개의 ing 중에 첫번째 ing만 바뀜
gsub("ing", "ING", mysentence)    # 두개의 ing 중에 둘 다 바뀜

# 고유명사 전처리
r_wiki_sent
sent1 <- r_wiki_sent[[1]][1]
gsub("R Foundation for Statistical Computing", "R_Foundation_for_Statistical_Computing", sent1)


sent1
strsplit(sent1, split = " ")
class(strsplit(sent1, split = " "))
table(strsplit(sent1, split = " "))    # 각 단어가 몇번 나오는지
sum(table(strsplit(sent1, split = " ")))    # 전체 단어 개수의 합


new.sent1 <- gsub("R Foundation for Statistical Computing", "R_Foundation_for_Statistical_Computing", sent1)
sum(table(strsplit(new.sent1, split = " ")))

# 특정 단어 제거 (gsub 이용)
gsub("and", "", new.sent1)
drop.sent1 <- gsub("and |by |for |the ", "", new.sent1)
strsplit(drop.sent1, split = " ")
table(strsplit(drop.sent1, split = " "))
sum(table(strsplit(drop.sent1, split = " ")))
```

### regmatches

```R
regexpr("ing", mysentence)   # 이걸 보통 패턴식이라고 한다. 패턴식을 변수에 넣기도 한다.
# 패턴 저장
mypattern <- regexpr("ing", mysentence)
# 패턴과 매치되는 문자열 추출
regmatches(mysentence, mypattern)

mypattern <- gregexpr("ing", mysentence)
regmatches(mysentence, mypattern)
```

### invert 옵션: 해당 표현을 제외

```R
mypattern <- regexpr("ing", mysentence)
regmatches(mysentence, mypattern, invert = T)    # "ing"를 뺀 나머지를 추출

mypattern <- gregexpr("ing", mysentence)
regmatches(mysentence, mypattern, invert = T)
```

### substr

```R
mysentences
substr(mysentences, 1, 30)   #각 문장별로 1~30번째 글자까지 추출
```

### ing로 끝나는 모든 단어를 추출하기

```R
my2sentence <- c("Learning R is so interesting", "He is a fascinating singer")

# 주의! ing로 '끝나는' 단어만 추출 (즉, singer에서는 추출하면 안된다)
regexpr("ing", my2sentence)    # 각 문장에서 첫번째 ing만 찾는다
gregexpr("ing", my2sentence)    # 모든 ing를 찾는다

mypattern0 <- gregexpr("ing", my2sentence)
regmatches(my2sentence, mypattern0)

# 조건: ing 앞에 알파벳만 올 수 있다
mypattern1 <- gregexpr("[[:alpha:]](ing)", my2sentence)    # ing 앞에 문자가 하나 나온다
regmatches(my2sentence, mypattern1)
# [[:alpha:]] 는 모든 알파벳 문자를 나타내는 정규표현식

# 근데 나는 ing 앞에 문자가 하나 이상, 완전한 단어로 나왔으면 좋겠다
# 조건: ing 앞에 최소 1회 이상 알파벳이 올 수 있다
mypattern2 <- gregexpr("[[:alpha:]]{1,}(ing)", my2sentence)    # {1,} : 한 글자 이상, 무한대까지
regmatches(my2sentence, mypattern2)
# 또는
mypattern2 <- gregexpr("[[:alpha:]]+(ing)", my2sentence)    # +는 {1,}와 같은 의미이다.
regmatches(my2sentence, mypattern2)

# 조건: ing로 끝나야 한다
mypattern3 <- gregexpr("[[:alpha:]]{1,}(ing)\\b", my2sentence)    # \\b : 끝난다는 표시
regmatches(my2sentence, mypattern3)
```

```R
mysentences
mypattern <- gregexpr("[[:alpha:]]{1,}(ing)\\b", mysentences)
myings <- regmatches(mysentences, mypattern)
myings
unlist(myings)
table(unlist(myings))    # computing이 소문자/대문자 때문에 다른 단어로 처리된다

# 대소문자를 일괄 통일
mypattern <- gregexpr("[[:alpha:]]{1,}(ing)\\b", tolower(mysentences))
myings <- regmatches(tolower(mysentences), mypattern)
myings
unlist(myings)
table(unlist(myings))
```



