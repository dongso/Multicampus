# 앞으로 할 것들

추천하는 목요일 개인 프로젝트

1. 영화 review 감성 분석
2. 신문 기사 감성 분석
3. 제품 review 감성 분석
4. 지식인 Q&A 분석 (예, 키워드 검색 -> 스크래핑)



# 실수 방지 리뷰

## 리스트 관련 변수 다루기

```R
a <- list(1,2,3)
length(a)    # list a의 요소의 개수가 출력

seq(5,10)
class(seq(5,10))
b <- as.list(seq(5,10))
b             

e <- as.list(seq(5,10))
length(e)
length(e)-1
# list e에서 "9"라는 요소를 참조하고 싶을 때
e[[5]]
# list e에서 "9"라는 요소를 참조해서 "9"를 "99"로 변경하려고 할 때
e[[length(e)-1]] <- 99
e
```

### 리스트에서 자료 삭제

```R
c <- as.list(seq(10,14))
c
# c의 첫번째 요소인 "10"이라는 데이터를 삭제하고 싶다
c[[1]] <- NULL    # 리스트에서 특정 자료 삭제 시 NULL을 집어넣어주면 된다
c
# c에서 "13"도 삭제
c[[3]] <- NULL
c
```

### Subset

subset: 특정 범위의 자료를 가져올 수 있다

```R
d <- as.list(seq(20))
d[10:15]    # 특정 범위를 가져온다

# 여러개의 벡터를 좌우로 합치면 (cbind, rbind) 행렬이 된다
# matrix

matrix(1:6, ncol=3, byrow=T)    # byrow로 하면 데이터가 행부터 순서대로 입력된다. default는 열부터 순서대로 입력.

cbind(c(1,2),c(3,4))
rbind(c(1,2),c(3,4))

# length: 벡터이든 행렬이든 상관없이 전체 원소 개수가 구해진다
a <- c(1,2,3)
b <- rbind(c(1,2),c(3,4))
length(a)
length(b)
# dim: 벡터의 경우에는 NULL, 행렬의 경우에는 크기 벡터 출력
dim(a)
dim(b)
```

### 벡터 인덱싱, 서브셋팅

벡터 인덱싱: [[]]

서브셋팅:[]

```R
a[1]
a[1:2]
a[[1]]

a <- rbind(1:4, 6:9)
a
# a에서 "8"을 참조하여 출력
a[]    # 전체
a[1,]    # 첫번째 행
a[,2]    # 두번째 열
a[2,2:4]    # 두번째 행의 2~4열
a[1:2, 2:3]    # 1~2행, 2~3열
a[2,3]    # 2행 3열 = 8
a[[2,3]]
```

### 빼기

```R
a <- 1:10
a
b <- a[-5]
b
a[7:9]
a[-7:-9]
```

### TRUE/FALSE

```R
bl <- c(T,F,T,T)
k <- 1:4
k[bl]    # k에서 true에 해당하는 것들만 출력
k[k%%2==0]    # k에서 2로 나눴을 때 나머지가 0인 것들만 출력

k <- k*10
k
```

### 변수 초기화

```R
rep(NA,10)    # 초기화 작업을 할 때 rep 함수가 유용하게 사용될 수 있다

seq (0,100, length=5)    # 0에서 100까지 등분해서 다섯개의 수를 만든다

set.seed(1)
rnorm(10)    # 가우시안 정규분포를 따르는 난수를 만든다.
# seed값을 어떻게 주느냐에 따라 난수 값이 다르게 나온다. seed값이 같으면 나오는 난수 값도 동일하다.
runif(10)    # 역시 난수를 만드는 함수지만, 0~1 사이를 구간으로 나눈 후 균등하게 분포되도록 난수를 만든다.

matrix(rnorm(10), c(2,5))
```

### 시간 측정

```R
x <- 1:10000
y <- 10001:20000
proc.time()    # 어느 정도 시간이 걸렸는지 알 수 있다

startTime <- proc.time()
z <- rep(0,10000)
z[1] <- x[1] + y[1]
for (i in 1:10000){
  z[i] <- x[i] + y[i]
}
proc.time()-startTime    # 경과 시간
```

### 비교

```R
a <- c(1,2,3)
b <- c(4,2,1)
a==b    # a와 b가 같은지 각 요소끼리 비교해 확인 => 결과가 요소 길이만큼 나온다.
all(a==b)    # 모든 요소가 같은지를 비교 => 결과가 하나 나온다.
```

### log

```R
exp(a)

a <- c(0,1,2,3)
log(a)
log10(a)
```

### broadcasting

broadcasting: shape을 맞춰주기 위해 확장되는 것

```R
x <- 1:5
y <- rep(1, length(x))
x+y    # 요소끼리 더한다
x+2    # x는 요소가 5개인데 2는 스칼라이다. 이럴 때 2가 확장되는데 이를 broadcasting이라고 한다. shape을 맞춰주기 위해 확장되는 것.
```

### which.max

```R
x <- 50:59
max(x)
which.max(x)    # max값이 있는 곳의 index(위치)가 리턴된다.
```

### colSums

```R
x <- matrix(c(10,20,10,20), nrow = 2)
# 각 열의 합계 출력
sum(x[,1])
sum(x[,2])
colSums(x)
```

### 분류

```R
set.seed(123)
df <- data.frame(k1 = c("x", "x", "y", "y", "x"),
                 k2 = c("f", "s", "f", "s", "f"),
                 d1 = rnorm(5),
                 d2 = rnorm(5))
df

library(dplyr)
group_by(df, k1)
summarise(group_by(df, k1), myMean=mean(d1))
df
# 두개의 기준으로 분류하고 싶을 때
summarise(group_by(df, k1, k2), myMean=mean(d1))
```

### 데이터 정리정돈

```R
install.packages("tidyr")    # 데이터 정리/정돈 패키지
library(tidyr)

# spread(): 피벗테이블 형태로 변경해주는 함수.
summarise(group_by(df, k1, k2), myMean=mean(d1)) 
spread(summarise(group_by(df, k1, k2), myMean=mean(d1)), k2, myMean)
spread(summarise(group_by(df, k1, k2), myMean=mean(d1)), k1, myMean)
```

### 데이터프레임 합성

* 두 데이터프레임 합성 => join, merge
* bind: 단순 연결
* merge: 두 df의 공통된 key를 사용해서 병합.

```R
df1 <- data.frame(k=c("b", "b", "a", "c", "a", "a", "b"),
                  d1=0:6)
df1
df2 <- data.frame(k=c("a", "b", "d"), d2=0:2)
df2
merge(df1,df2)    # k를 기준으로 합침.
merge(df1,df2, all=T)    # 공통된 key가 없을 때에도 출력
merge(df1,df2, all.x = T)    # 공통된 key가 없을 때에도 첫번째 행렬의 인자는 다 출력
merge(df1,df2, all.y = T)    # 공통된 key가 없을 때에도 두번째 행렬의 인자는 다 출력
```



# 감성 분석

```R
install.packages("tidytext")
library(tidytext)
get_sentiments("afinn")
summary(get_sentiments("afinn"))
AFINN <- data.frame(get_sentiments("afinn"))

# AFINN 시각화
hist(AFINN$score)
hist(AFINN$score, xlim = c(-6,6), col="blue", breaks = 20)

# bing, nrc
get_sentiments("bing")
get_sentiments("nrc")

oplex <- data.frame(get_sentiments("bing"))
table(oplex$sentiment)

emolex <- data.frame(get_sentiments("nrc"))
table(emolex$sentiment)

emolex$word[emolex$sentiment=="anger"]
```

## 논문 자료 감성 분석

```R
library(tm)
library(stringr)
library(dplyr)

my.text.location <- "Data/papers/"
mypaper <- VCorpus(DirSource(my.text.location))
inspect(mypaper)

mypaper[[1]]
str(mypaper[[1]])

mypaper[[1]]$content
class(mypaper[[1]]$content)    # 문자 벡터

mypaper[[1]][1]
class(mypaper[[1]][1])    # 리스트
unlist(mypaper[[1]][1])    # 벡터화
class(unlist(mypaper[[1]][1]))
as.character(mypaper[[1]][1])

length(as.character(mypaper[[1]][1]))
length(unlist(mypaper[[1]][1]))    # 1



mytext <- c(rep(NA,24))
for (i in 1:24){
  mytext[i] <- as.character(mypaper[[i]][1])
}
mytext[24]



# data_frame(): tidytext 형태로 데이터를 구성. 감성분석할때 좋다. tibble과 비슷. data.frame보다 개선된 타입.
data_frame(paper.id=1:24, doc = mytext)
my.df.text <- data_frame(paper.id=1:24, doc = mytext)
my.df.text

my.df.text %>% 
  unnest_tokens(word,doc)
# 문서 단위의 텍스트를 단어로 분해하는 함수 = unnest_tokens()

my.df.text.word <- my.df.text %>% unnest_tokens(word,doc)
my.df.text.word



get_sentiments("bing")



      # join 연습

      # creating dataframe1
      pd=data.frame(Name=c("Senthil","Senthil","Sam","Sam"),
                    Month=c("Jan","Feb","Jan","Feb"),
                    BS = c(141.2,139.3,135.2,160.1),
                    BP = c(90,78,80,81))
      print(pd)
      # creating dataframe2
      pd_new=data.frame(Name=c("Senthil","Ramesh","Sam"), Department=c("PSE","Data Analytics","PSE"))
      print(pd_new) 
      # join
      left_join(pd,pd_new, by="Name")
      right_join(pd,pd_new, by="Name")
      inner_join(pd,pd_new, by="Name")    # 같은 것끼리 join



my.df.text.word %>% 
  inner_join(get_sentiments("bing"))

my.df.text.word %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(word, paper.id, sentiment)    # 결과에서 n은 등장 횟수

myresult.sa <- my.df.text.word %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(word, paper.id, sentiment) %>% 
  spread(sentiment, n, fill = 0)
myresult.sa

group_by(myresult.sa, paper.id)
myagg <- summarise(group_by(myresult.sa, paper.id),
          pos.sum = sum(positive),
          neg.sum = sum(negative),
          pos.sent = pos.sum-neg.sum)
myagg

# myagg의 네 열 옆에 파일명과 발행년도를 새 열로 추가하기

myfilenames <- list.files(path = my.text.location, all.files = T)
paper.name <- myfilenames[3:26]

pub.year <- as.numeric(unlist(str_extract_all(paper.name, "[[:digit:]]{4}")))
pub.year

paper.id <- 1:24
pub.year.df <- data.frame(paper.id, paper.name, pub.year)
pub.year.df
```



